{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF as NMF_sklearn\n",
    "import pickle\n",
    "from nmf import NMF\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import pickle\n",
    "def build_text_vectorizer(contents, use_tfidf=True, use_stemmer=False, max_features=None):\n",
    "    '''\n",
    "    Build and return a **callable** for transforming text documents to vectors,\n",
    "    as well as a vocabulary to map document-vector indices to words from the\n",
    "    corpus. The vectorizer will be trained from the text documents in the\n",
    "    `contents` argument. If `use_tfidf` is True, then the vectorizer will use\n",
    "    the Tf-Idf algorithm, otherwise a Bag-of-Words vectorizer will be used.\n",
    "    The text will be tokenized by words, and each word will be stemmed iff\n",
    "    `use_stemmer` is True. If `max_features` is not None, then the vocabulary\n",
    "    will be limited to the `max_features` most common words in the corpus.\n",
    "    '''\n",
    "    \n",
    "    Vectorizer = TfidfVectorizer if use_tfidf else CountVectorizer\n",
    "    tokenizer = RegexpTokenizer(r\"[\\w']+\")\n",
    "    stem = PorterStemmer().stem if use_stemmer else (lambda x: x)\n",
    "    stop_set = set(stopwords.words('english'))\n",
    "\n",
    "    # Closure over the tokenizer et al.\n",
    "    def tokenize(text):\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        stems = [stem(token) for token in tokens if token not in stop_set]\n",
    "        return stems\n",
    "\n",
    "    vectorizer_model = Vectorizer(tokenizer=tokenize, max_features=max_features)\n",
    "    vectorizer_model.fit(contents)\n",
    "    vocabulary = np.array(vectorizer_model.get_feature_names())\n",
    "\n",
    "    # Closure over the vectorizer_model's transform method.\n",
    "    def vectorizer(X):\n",
    "        return vectorizer_model.transform(X).toarray()\n",
    "\n",
    "    return vectorizer, vocabulary\n",
    "\n",
    "\n",
    "def softmax(v, temperature=1.0):\n",
    "    '''\n",
    "    A heuristic to convert arbitrary positive values into probabilities.\n",
    "    See: https://en.wikipedia.org/wiki/Softmax_function\n",
    "    '''\n",
    "    expv = np.exp(v / temperature)\n",
    "    s = np.sum(expv)\n",
    "    return expv / s\n",
    "\n",
    "\n",
    "def hand_label_topics(H, vocabulary):\n",
    "    '''\n",
    "    Print the most influential words of each latent topic, and prompt the user\n",
    "    to label each topic. The user should use their humanness to figure out what\n",
    "    each latent topic is capturing.\n",
    "    '''\n",
    "    hand_labels = []\n",
    "    for i, row in enumerate(H):\n",
    "        top_five = np.argsort(row)[::-1][:20]\n",
    "        print('topic', i)\n",
    "        print('-->', ' '.join(vocabulary[top_five]))\n",
    "        label = input('please label this topic: ')\n",
    "        hand_labels.append(label)\n",
    "        print()\n",
    "    return hand_labels\n",
    "\n",
    "\n",
    "def analyze_article(article_index, contents, web_urls, W, hand_labels):\n",
    "    '''\n",
    "    Print an analysis of a single NYT articles, including the article text\n",
    "    and a summary of which topics it represents. The topics are identified\n",
    "    via the hand-labels which were assigned by the user.\n",
    "    '''\n",
    "    #print(web_urls[article_index])\n",
    "    #print(contents[article_index])\n",
    "    probs = softmax(W[article_index], temperature=0.01)\n",
    "    \n",
    "    top_prob = 0\n",
    "    top_cat = 0\n",
    "    i = 0\n",
    "    for prob, label in zip(probs, hand_labels):\n",
    "        if prob > top_prob:\n",
    "            top_prob = prob\n",
    "            top_cat = i\n",
    "        #print('--> {:.2f}% {}'.format(prob * 100, label))\n",
    "        i = i + 1\n",
    "    return top_cat, probs\n",
    "    #print()\n",
    "    #    gotta assign all of these to the correct bin and then tfidf them \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/all-the-news/articles1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'title', 'publication', 'author', 'date', 'year',\n",
       "       'month', 'url', 'content'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df1 = pd.read_csv('data/all-the-news/articles1.csv')\n",
    "g_df2 = pd.read_csv('data/all-the-news/articles2.csv')\n",
    "g_df3 = pd.read_csv('data/all-the-news/articles3.csv')\n",
    "\n",
    "g_arr1 = g_df1.values\n",
    "g_arr2 = g_df2.values\n",
    "g_arr3 = g_df3.values\n",
    "\n",
    "g_df_full = g_df1.append(g_df2).append(g_df3)\n",
    "g_df_reset=g_df_full.reset_index(drop=True)\n",
    "g_df_reset.head()\n",
    "g_df_reset.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "g_df_full = g_df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_array = np.concatenate((g_arr1,g_arr2,g_arr3),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Breitbart              23781\n",
       "New York Post          17493\n",
       "NPR                    11992\n",
       "CNN                    11488\n",
       "Washington Post        11114\n",
       "Reuters                10710\n",
       "Guardian                8681\n",
       "New York Times          7803\n",
       "Atlantic                7179\n",
       "Business Insider        6757\n",
       "National Review         6203\n",
       "Talking Points Memo     5214\n",
       "Vox                     4947\n",
       "Buzzfeed News           4854\n",
       "Fox News                4354\n",
       "Name: publication, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df_full['publication'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51831"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23781+17493+6203+4354\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39582"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lib\n",
    "11488+11114+7179+4947+4854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = \n",
    "def balance_outlets():\n",
    "    sklearn.model_selection.train_test_split(,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17283</td>\n",
       "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17284</td>\n",
       "      <td>Rift Between Officers and Residents as Killing...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Benjamin Mueller and Al Baker</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After the bullet shells get counted, the blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17285</td>\n",
       "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Margalit Fox</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17286</td>\n",
       "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>William McDonald</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17287</td>\n",
       "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Choe Sang-Hun</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                              title  \\\n",
       "0           0  17283  House Republicans Fret About Winning Their Hea...   \n",
       "1           1  17284  Rift Between Officers and Residents as Killing...   \n",
       "2           2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...   \n",
       "3           3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
       "4           4  17287  Kim Jong-un Says North Korea Is Preparing to T...   \n",
       "\n",
       "      publication                         author        date    year  month  \\\n",
       "0  New York Times                     Carl Hulse  2016-12-31  2016.0   12.0   \n",
       "1  New York Times  Benjamin Mueller and Al Baker  2017-06-19  2017.0    6.0   \n",
       "2  New York Times                   Margalit Fox  2017-01-06  2017.0    1.0   \n",
       "3  New York Times               William McDonald  2017-04-10  2017.0    4.0   \n",
       "4  New York Times                  Choe Sang-Hun  2017-01-02  2017.0    1.0   \n",
       "\n",
       "   url                                            content  \n",
       "0  NaN  WASHINGTON  —   Congressional Republicans have...  \n",
       "1  NaN  After the bullet shells get counted, the blood...  \n",
       "2  NaN  When Walt Disney’s “Bambi” opened in 1942, cri...  \n",
       "3  NaN  Death may be the great equalizer, but it isn’t...  \n",
       "4  NaN  SEOUL, South Korea  —   North Korea’s leader, ...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17283</td>\n",
       "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17284</td>\n",
       "      <td>Rift Between Officers and Residents as Killing...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Benjamin Mueller and Al Baker</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After the bullet shells get counted, the blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17285</td>\n",
       "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Margalit Fox</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17286</td>\n",
       "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>William McDonald</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17287</td>\n",
       "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Choe Sang-Hun</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title     publication  \\\n",
       "0  17283  House Republicans Fret About Winning Their Hea...  New York Times   \n",
       "1  17284  Rift Between Officers and Residents as Killing...  New York Times   \n",
       "2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...  New York Times   \n",
       "3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...  New York Times   \n",
       "4  17287  Kim Jong-un Says North Korea Is Preparing to T...  New York Times   \n",
       "\n",
       "                          author        date    year  month  url  \\\n",
       "0                     Carl Hulse  2016-12-31  2016.0   12.0  NaN   \n",
       "1  Benjamin Mueller and Al Baker  2017-06-19  2017.0    6.0  NaN   \n",
       "2                   Margalit Fox  2017-01-06  2017.0    1.0  NaN   \n",
       "3               William McDonald  2017-04-10  2017.0    4.0  NaN   \n",
       "4                  Choe Sang-Hun  2017-01-02  2017.0    1.0  NaN   \n",
       "\n",
       "                                             content  \n",
       "0  WASHINGTON  —   Congressional Republicans have...  \n",
       "1  After the bullet shells get counted, the blood...  \n",
       "2  When Walt Disney’s “Bambi” opened in 1942, cri...  \n",
       "3  Death may be the great equalizer, but it isn’t...  \n",
       "4  SEOUL, South Korea  —   North Korea’s leader, ...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df_reset.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "g_df_reset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142570, 9)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df_reset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 17283,\n",
       "       'House Republicans Fret About Winning Their Health Care Suit - The New York Times',\n",
       "       'New York Times', 'Carl Hulse', '2016-12-31', 2016.0, 12.0, nan,\n",
       "       'WASHINGTON  —   Congressional Republicans have a new fear when it comes to their    health care lawsuit against the Obama administration: They might win. The incoming Trump administration could choose to no longer defend the executive branch against the suit, which challenges the administration’s authority to spend billions of dollars on health insurance subsidies for   and   Americans, handing House Republicans a big victory on    issues. But a sudden loss of the disputed subsidies could conceivably cause the health care program to implode, leaving millions of people without access to health insurance before Republicans have prepared a replacement. That could lead to chaos in the insurance market and spur a political backlash just as Republicans gain full control of the government. To stave off that outcome, Republicans could find themselves in the awkward position of appropriating huge sums to temporarily prop up the Obama health care law, angering conservative voters who have been demanding an end to the law for years. In another twist, Donald J. Trump’s administration, worried about preserving executive branch prerogatives, could choose to fight its Republican allies in the House on some central questions in the dispute. Eager to avoid an ugly political pileup, Republicans on Capitol Hill and the Trump transition team are gaming out how to handle the lawsuit, which, after the election, has been put in limbo until at least late February by the United States Court of Appeals for the District of Columbia Circuit. They are not yet ready to divulge their strategy. “Given that this pending litigation involves the Obama administration and Congress, it would be inappropriate to comment,” said Phillip J. Blando, a spokesman for the Trump transition effort. “Upon taking office, the Trump administration will evaluate this case and all related aspects of the Affordable Care Act. ” In a potentially   decision in 2015, Judge Rosemary M. Collyer ruled that House Republicans had the standing to sue the executive branch over a spending dispute and that the Obama administration had been distributing the health insurance subsidies, in violation of the Constitution, without approval from Congress. The Justice Department, confident that Judge Collyer’s decision would be reversed, quickly appealed, and the subsidies have remained in place during the appeal. In successfully seeking a temporary halt in the proceedings after Mr. Trump won, House Republicans last month told the court that they “and the  ’s transition team currently are discussing potential options for resolution of this matter, to take effect after the  ’s inauguration on Jan. 20, 2017. ” The suspension of the case, House lawyers said, will “provide the   and his future administration time to consider whether to continue prosecuting or to otherwise resolve this appeal. ” Republican leadership officials in the House acknowledge the possibility of “cascading effects” if the   payments, which have totaled an estimated $13 billion, are suddenly stopped. Insurers that receive the subsidies in exchange for paying    costs such as deductibles and   for eligible consumers could race to drop coverage since they would be losing money. Over all, the loss of the subsidies could destabilize the entire program and cause a lack of confidence that leads other insurers to seek a quick exit as well. Anticipating that the Trump administration might not be inclined to mount a vigorous fight against the House Republicans given the  ’s dim view of the health care law, a team of lawyers this month sought to intervene in the case on behalf of two participants in the health care program. In their request, the lawyers predicted that a deal between House Republicans and the new administration to dismiss or settle the case “will produce devastating consequences for the individuals who receive these reductions, as well as for the nation’s health insurance and health care systems generally. ” No matter what happens, House Republicans say, they want to prevail on two overarching concepts: the congressional power of the purse, and the right of Congress to sue the executive branch if it violates the Constitution regarding that spending power. House Republicans contend that Congress never appropriated the money for the subsidies, as required by the Constitution. In the suit, which was initially championed by John A. Boehner, the House speaker at the time, and later in House committee reports, Republicans asserted that the administration, desperate for the funding, had required the Treasury Department to provide it despite widespread internal skepticism that the spending was proper. The White House said that the spending was a permanent part of the law passed in 2010, and that no annual appropriation was required  —   even though the administration initially sought one. Just as important to House Republicans, Judge Collyer found that Congress had the standing to sue the White House on this issue  —   a ruling that many legal experts said was flawed  —   and they want that precedent to be set to restore congressional leverage over the executive branch. But on spending power and standing, the Trump administration may come under pressure from advocates of presidential authority to fight the House no matter their shared views on health care, since those precedents could have broad repercussions. It is a complicated set of dynamics illustrating how a quick legal victory for the House in the Trump era might come with costs that Republicans never anticipated when they took on the Obama White House.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49999, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_arr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02576601, 0.61020692, 0.05870463, 0.22437147, 0.02064656,\n",
       "       0.02707373, 0.03323069])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_probs_for_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-83b7215324b4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-83b7215324b4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    {bane:2, i:g_probs_for_clusters[i] for i in range(0,len(g_probs_for_clusters))}[1]\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "{ i:g_probs_for_clusters[i] for i in range(0,len(g_probs_for_clusters))}[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142570, 9)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guardian'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bane.update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error: 358.7721134427164\n",
      "topic 0\n",
      "--> says like people one women time get think even way know life would first new years really us world going\n",
      "\n",
      "topic 1\n",
      "--> trump donald president republican campaign house cruz said republicans white election gop would presidential party obama nominee ryan news administration\n",
      "\n",
      "topic 2\n",
      "--> u russia said syria obama military united president russian korea north syrian government islamic state iran isis security states war\n",
      "\n",
      "topic 3\n",
      "--> percent company billion said 1 u million market companies year 2 tax new bank growth would 5 0 health investors\n",
      "\n",
      "topic 4\n",
      "--> clinton sanders hillary democratic campaign voters state presidential bernie party emails election email fbi obama candidate democrats vote nominee comey\n",
      "\n",
      "topic 5\n",
      "--> police said officers court officer told shooting man department city law authorities shot killed gun according county video arrested investigation\n",
      "\n",
      "topic 6\n",
      "--> mr ms said mrs united j new would _____ f york b party states former years senator campaign officials times\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \"\"\"\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-40574a532caa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mg_H\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_nmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reconstruction error:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_nmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruction_err_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mg_hand_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhand_label_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_vocabulary\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ['Garbage', 'GOP', 'Intl Politics', 'Econ', 'Dems', 'Crime', 'Election'] #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-01b225d438fd>\u001b[0m in \u001b[0;36mhand_label_topics\u001b[0;34m(H, vocabulary)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'topic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-->'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_five\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'please label this topic: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mhand_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "#fix\n",
    "#g_df1 = g_df_full #pd.read_csv('data/all-the-news/articles1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142570, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0*len(g_rand_articles),1*len(g_rand_articles)):\n",
    "    #print('before db insert')\n",
    "    g_clus, g_probs_for_clusters= analyze_article(i, g_contents, g_web_urls, g_W, g_hand_labels)\n",
    "\n",
    "    cl = MongoClient()\n",
    "    g_coll = cl[\"cluster_all\"][\"seven_clusters\"]\n",
    "\n",
    "    data = {\"_id\" : i, \"content\" : str(g_contents[i]), \"highest_cluster\" : g_clus}\n",
    "    for i in range(0,len(g_probs_for_clusters)):\n",
    "        data[str(i)] = g_probs_for_clusters[i]\n",
    "    g_coll.insert_one(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'cluster_all'), 'seven_clusters')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_df_full.drop(columns=['Unnamed:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0931962467000906"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_probs_for_clusters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142570"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142570"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list('AB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/all-the-news/articles3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'title', 'publication', 'author', 'date', 'year',\n",
       "       'month', 'url', 'content'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = g_vectorizer(test_df.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42571, 5000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_files(f1name,f2name,f3name):\n",
    "    with open(f1name) as f1:\n",
    "        cont1 = f1.readlines()\n",
    "        print(len(cont1))\n",
    "    with open(f2name) as f2:\n",
    "        cont2 = f2.readlines()\n",
    "        print(len(cont2))\n",
    "    with open(f3name) as f3:\n",
    "        cont3 = f3.readlines()\n",
    "        print(len(cont3))\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50008\n",
      "79477\n",
      "55718\n"
     ]
    }
   ],
   "source": [
    "merge_files('data/all-the-news/articles1.csv','data/all-the-news/articles2.csv','data/all-the-news/articles3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185203"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50008+79477+55718"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  1  2\n",
       "1  3  4\n",
       "0  1  2\n",
       "1  3  4"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.append(df_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = pd.Series('election')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=g_vectorizer(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result=g_nmf.transform(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.00819077, 0.        , 0.        , 0.01120118]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142570, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_nmf(heldout_name,train_data):\n",
    "    #make_names:\n",
    "    vectorizer_file_name = 'cache/'+heldout_name+' vectorizer'\n",
    "    vocabulary_file_name = 'cache/'+heldout_name+' vocabulary'\n",
    "    nmf_file_name = 'cache/'+heldout_name+' nmf'\n",
    "    \n",
    "    g_df = train_data \n",
    "    g_contents = g_df.content\n",
    "    g_web_urls = g_df.url\n",
    "\n",
    "    # Build our text-to-vector vectorizer, then vectorize our corpus.\n",
    "    g_vectorizer, g_vocabulary = build_text_vectorizer(g_contents,\n",
    "                                 use_tfidf=True,\n",
    "                                 use_stemmer=False,\n",
    "                                 max_features=5000)\n",
    "    g_X = g_vectorizer(g_contents)\n",
    "\n",
    "    # We'd like to see consistent results, so set the seed.\n",
    "    np.random.seed(12345)\n",
    "\n",
    "    #g_rand_articles = list(range(len(g_df_full)))\n",
    "    #for i in rand_articles:\n",
    "    #        analyze_article(i, contents, web_urls, W, hand_labels)\n",
    "\n",
    "    # Do it all again, this time using scikit-learn.\n",
    "    g_nmf = NMF_sklearn(n_components=6, max_iter=100, random_state=12345, alpha=0.0)\n",
    "    g_W = g_nmf.fit_transform(g_X)\n",
    "    g_H = g_nmf.components_\n",
    "    print('reconstruction error:', g_nmf.reconstruction_err_)\n",
    "    #g_hand_labels = ['label_one', 'label_two', 'label_three', 'label_four', 'label_five', 'label_one'] # hand_label_topics(g_H, g_vocabulary) #\n",
    "    \n",
    "    #pickle.dump(g_vectorizer,open(vectorizer_file_name,'wb'))\n",
    "    #pickle.dump(g_vocabulary,open(vocabulary_file_name,'wb'))\n",
    "    #pickle.dump(g_nmf,open(nmf_file_name,'wb'))\n",
    "    \n",
    "    return g_vectorizer, g_vocabulary, g_nmf\n",
    "#pickle.dump(H,open('nyt_clusters_H.p','wb'))\n",
    "#pickle.dump(W,open('nyt_clusters_W.p','wb'))\n",
    "\n",
    "def train_random_forest(cleaned_nmf_compenents, raw_training_data, cleaned_train_y,trees_in_forest = 100):\n",
    "    print('trees in this forest: ', trees_in_forest)\n",
    "    #outlets = raw_training_data['publication']\n",
    "    #y_train = pd.Series([outlet_leaning[outlet] for outlet in outlets])\n",
    "    y_train = cleaned_train_y\n",
    "    X_train = cleaned_nmf_compenents\n",
    "    rf = RandomForestClassifier(n_estimators=trees_in_forest, oob_score=True)\n",
    "    rf.fit(X_train, y_train)\n",
    "    #print(\"\\n11: accuracy score:\", rf.score(X_test, y_test))\n",
    "    #print(\"    out of bag score:\", rf.oob_score_)\n",
    "    return rf\n",
    "\n",
    "def read_in_raw_data():\n",
    "    g_df1 = pd.read_csv('data/all-the-news/articles1.csv')\n",
    "    g_df2 = pd.read_csv('data/all-the-news/articles2.csv')\n",
    "    g_df3 = pd.read_csv('data/all-the-news/articles3.csv')\n",
    "\n",
    "    g_arr1 = g_df1.values\n",
    "    g_arr2 = g_df2.values\n",
    "    g_arr3 = g_df3.values\n",
    "\n",
    "    g_df_full = g_df1.append(g_df2).append(g_df3)\n",
    "    g_df_reset=g_df_full.reset_index(drop=True)\n",
    "    g_df_reset.head()\n",
    "    g_df_reset.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    g_df_full = g_df_reset\n",
    "    return g_df_full\n",
    "    \n",
    "def get_test_train(heldout,data):\n",
    "    return data[(data['publication'] != heldout)], data[(data['publication'] == heldout)]\n",
    "    \n",
    "def predictions():\n",
    "    pass\n",
    "\n",
    "    \n",
    "def evaluate_model(vectorizer, vocabulary, nmf, heldout_outlet, test_data,outlets):\n",
    "    train_data, test_data = get_test_train(heldout,data)\n",
    "    \n",
    "    \n",
    "#maybe remove wapo\n",
    "def kfolds():\n",
    "    #outlets =[('Fox News',1),('National Review',1),('National Review',1),('New York Post',1),('Breitbart',1),\n",
    "    #          ('Buzzfeed News',0),('Vox',0)('Atlantic',0),('Washington Post',0),('CNN',0)]\n",
    "    outlets =['Fox News','National Review','National Review','New York Post','Breitbart',\n",
    "              'Buzzfeed News','Vox','Atlantic','Washington Post','CNN']\n",
    "    leanings_dict = {'Fox News':1,'National Review':1,'National Review':1,'New York Post':1,'Breitbart':1,\n",
    "              'Buzzfeed News':0,'Vox':0,'Atlantic':0,'Washington Post':0,'CNN':0}\n",
    "    \n",
    "    data = read_in_raw_data()\n",
    "    \n",
    "    \n",
    "    for heldout_outlet in outlets:\n",
    "        #tmp = [train_outlet for train_outlets in outlets if train_outlet != outlet]\n",
    "        train_data, test_data = get_test_train(heldout_outlet,data)\n",
    "        #model specific below\n",
    "        vectorizer, vocabulary, nmf = build_nmf(heldout_outlet,train_data)\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_weak_outlets(valid_outlets,leanings,train_set,labels):\n",
    "    assert(len(train_set)==len(labels))\n",
    "    joined_data = zip(labels,train_set)\n",
    "    cleaned_data = []\n",
    "    cleaned_label = []\n",
    "    cleaned_outlet = []\n",
    "    #= pd.DataFrame([row[1] for row in joined_data if row[0] in valid_outlets])\n",
    "    for row in joined_data:\n",
    "        if row[0] in valid_outlets:\n",
    "            cleaned_data.append(row[1])\n",
    "            cleaned_outlet.append(row[0])\n",
    "            cleaned_label.append(leanings[row[0]])\n",
    "            #print('row0: ',row[0])\n",
    "            #print('leanings[row[0]]: ',leanings[row[0]])\n",
    "    return pd.DataFrame(cleaned_data), pd.Series(cleaned_outlet), pd.Series(cleaned_label)\n",
    "    #for label in labels:\n",
    "       # if label in valid_outlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    outlets =['Fox News','National Review','New York Post','Breitbart',\n",
    "                  'Buzzfeed News','Vox','Atlantic','Washington Post','CNN']\n",
    "    leanings_dict = {'Fox News':1,'National Review':1,'New York Post':1,'Breitbart':1,\n",
    "            'Buzzfeed News':0,'Vox':0,'Atlantic':0,'Washington Post':0,'CNN':0}\n",
    "\n",
    "    data = read_in_raw_data()\n",
    "    for heldout_outlet in outlets: \n",
    "        #heldout_outlet = 'Atlantic'\n",
    "        #tmp = [train_outlet for train_outlets in outlets if train_outlet != outlet]\n",
    "        train_data, test_data = get_test_train(heldout_outlet,data)\n",
    "        #model specific below\n",
    "        vectorizer, vocabulary, nmf = build_nmf(heldout_outlet,train_data)\n",
    "        vectorized_train_data = vectorizer(train_data['content'])\n",
    "        components = nmf.transform(vectorized_train_data)\n",
    "\n",
    "        vectorized_train_data = vectorizer(train_data['content'])\n",
    "        components = nmf.transform(vectorized_train_data)\n",
    "        cleaned_train_data, cleaned_train_df, cleaned_train_y = remove_weak_outlets(outlets,leanings_dict,components,train_data['publication'])\n",
    "\n",
    "        test_data=test_data.reset_index(drop=True)\n",
    "        test_X = nmf.transform(vectorizer(test_data['content'])) #pd.Series([vectorizer(article) for article in test_data['content']])\n",
    "\n",
    "        pub_type = leanings_dict[test_data['publication'][0]]\n",
    "        test_y = pd.Series([pub_type for i in range(0,len(test_data))])\n",
    "        print('Score for: ', heldout_outlet)\n",
    "        print(rand_forest.score(test_X, test_y))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_data, cleaned_train_df, cleaned_train_y = remove_weak_outlets(outlets,leanings_dict,components,train_data['publication'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = get_test_train('Fox News',g_df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4354, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17283</td>\n",
       "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17284</td>\n",
       "      <td>Rift Between Officers and Residents as Killing...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Benjamin Mueller and Al Baker</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After the bullet shells get counted, the blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17285</td>\n",
       "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Margalit Fox</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17286</td>\n",
       "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>William McDonald</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17287</td>\n",
       "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Choe Sang-Hun</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title     publication  \\\n",
       "0  17283  House Republicans Fret About Winning Their Hea...  New York Times   \n",
       "1  17284  Rift Between Officers and Residents as Killing...  New York Times   \n",
       "2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...  New York Times   \n",
       "3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...  New York Times   \n",
       "4  17287  Kim Jong-un Says North Korea Is Preparing to T...  New York Times   \n",
       "\n",
       "                          author        date    year  month  url  \\\n",
       "0                     Carl Hulse  2016-12-31  2016.0   12.0  NaN   \n",
       "1  Benjamin Mueller and Al Baker  2017-06-19  2017.0    6.0  NaN   \n",
       "2                   Margalit Fox  2017-01-06  2017.0    1.0  NaN   \n",
       "3               William McDonald  2017-04-10  2017.0    4.0  NaN   \n",
       "4                  Choe Sang-Hun  2017-01-02  2017.0    1.0  NaN   \n",
       "\n",
       "                                             content  \n",
       "0  WASHINGTON  —   Congressional Republicans have...  \n",
       "1  After the bullet shells get counted, the blood...  \n",
       "2  When Walt Disney’s “Bambi” opened in 1942, cri...  \n",
       "3  Death may be the great equalizer, but it isn’t...  \n",
       "4  SEOUL, South Korea  —   North Korea’s leader, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_grid_search():\n",
    "    trees = [100]\n",
    "    outlets =['Fox News','National Review','New York Post','Breitbart',\n",
    "                  'Buzzfeed News','Vox','Atlantic','Washington Post','CNN']\n",
    "    leanings_dict = {'Fox News':1,'National Review':1,'New York Post':1,'Breitbart':1,\n",
    "            'Buzzfeed News':0,'Vox':0,'Atlantic':0,'Washington Post':0,'CNN':0}\n",
    "\n",
    "    data = read_in_raw_data()\n",
    "    for heldout_outlet in outlets: \n",
    "        #heldout_outlet = 'Atlantic'\n",
    "        #tmp = [train_outlet for train_outlets in outlets if train_outlet != outlet]\n",
    "        train_data, test_data = get_test_train(heldout_outlet,data)\n",
    "        #model specific below\n",
    "        vectorizer, vocabulary, nmf = build_nmf(heldout_outlet,train_data)\n",
    "        vectorized_train_data = vectorizer(train_data['content'])\n",
    "        components = nmf.transform(vectorized_train_data)\n",
    "\n",
    "        vectorized_train_data = vectorizer(train_data['content'])\n",
    "        components = nmf.transform(vectorized_train_data)\n",
    "        cleaned_train_data, cleaned_train_df, cleaned_train_y = remove_weak_outlets(outlets,leanings_dict,components,train_data['publication'])\n",
    "\n",
    "        test_data=test_data.reset_index(drop=True)\n",
    "        test_X = nmf.transform(vectorizer(test_data['content'])) #pd.Series([vectorizer(article) for article in test_data['content']])\n",
    "\n",
    "        pub_type = leanings_dict[test_data['publication'][0]]\n",
    "        test_y = pd.Series([pub_type for i in range(0,len(test_data))])\n",
    "        \n",
    "        for tree_count in trees:\n",
    "            rand_forest = train_random_forest(cleaned_train_data, _, cleaned_train_y, trees_in_forest = tree_count)\n",
    "            print('Score for: ', heldout_outlet, 'with ',tree_count, ' trees')\n",
    "\n",
    "            print(rand_forest.score(test_X, test_y))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error: 354.3197000648747\n",
      "trees in this forest:  50\n",
      "Score for:  Fox News with  50  trees\n",
      "0.5716582452916859\n",
      "trees in this forest:  100\n",
      "Score for:  Fox News with  100  trees\n",
      "0.5920992191088654\n",
      "trees in this forest:  200\n",
      "Score for:  Fox News with  200  trees\n",
      "0.5927882406982086\n",
      "trees in this forest:  400\n",
      "Score for:  Fox News with  400  trees\n",
      "0.5950849793293523\n",
      "reconstruction error: 352.02396754845097\n",
      "trees in this forest:  50\n",
      "Score for:  National Review with  50  trees\n",
      "0.41544413993229085\n",
      "trees in this forest:  100\n",
      "Score for:  National Review with  100  trees\n",
      "0.42398839271320327\n",
      "trees in this forest:  200\n",
      "Score for:  National Review with  200  trees\n",
      "0.42608415282927614\n",
      "trees in this forest:  400\n",
      "Score for:  National Review with  400  trees\n",
      "0.4265677897791391\n",
      "reconstruction error: 336.28201629888196\n",
      "trees in this forest:  50\n",
      "Score for:  New York Post with  50  trees\n",
      "0.2942891442291202\n",
      "trees in this forest:  100\n",
      "Score for:  New York Post with  100  trees\n",
      "0.29737609329446063\n",
      "trees in this forest:  200\n",
      "Score for:  New York Post with  200  trees\n",
      "0.29606128165551937\n",
      "trees in this forest:  400\n",
      "Score for:  New York Post with  400  trees\n",
      "0.2959469502086549\n",
      "reconstruction error: 327.6000047474941\n",
      "trees in this forest:  50\n",
      "Score for:  Breitbart with  50  trees\n",
      "0.36184348849922204\n",
      "trees in this forest:  100\n",
      "Score for:  Breitbart with  100  trees\n",
      "0.3712207224254657\n",
      "trees in this forest:  200\n",
      "Score for:  Breitbart with  200  trees\n",
      "0.3682771960809049\n",
      "trees in this forest:  400\n",
      "Score for:  Breitbart with  400  trees\n",
      "0.3674782389302384\n",
      "reconstruction error: 353.5634723711977\n",
      "trees in this forest:  50\n",
      "Score for:  Buzzfeed News with  50  trees\n",
      "0.37474248042851255\n",
      "trees in this forest:  100\n",
      "Score for:  Buzzfeed News with  100  trees\n",
      "0.3646477132262052\n",
      "trees in this forest:  200\n",
      "Score for:  Buzzfeed News with  200  trees\n",
      "0.36011536876802636\n",
      "trees in this forest:  400\n",
      "Score for:  Buzzfeed News with  400  trees\n",
      "0.35599505562422745\n",
      "reconstruction error: 353.6136038001564\n",
      "trees in this forest:  50\n",
      "Score for:  Vox with  50  trees\n",
      "0.40024257125530627\n",
      "trees in this forest:  100\n",
      "Score for:  Vox with  100  trees\n",
      "0.3873054376389731\n",
      "trees in this forest:  200\n",
      "Score for:  Vox with  200  trees\n",
      "0.3784111582777441\n",
      "trees in this forest:  400\n",
      "Score for:  Vox with  400  trees\n",
      "0.38285829795835863\n",
      "reconstruction error: 350.8494738923189\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7e0330018b64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_grid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-81f90d47ca6a>\u001b[0m in \u001b[0;36mtest_grid_search\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mvectorized_train_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mcleaned_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcleaned_train_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcleaned_train_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_weak_outlets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutlets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleanings_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'publication'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/nmf.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'both'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             shuffle=self.shuffle)\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/nmf.py\u001b[0m in \u001b[0;36mnon_negative_factorization\u001b[0;34m(X, W, H, n_components, init, update_H, solver, beta_loss, tol, max_iter, alpha, l1_ratio, regularization, random_state, verbose, shuffle)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m     \u001b[0mcheck_non_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NMF (input X)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m     \u001b[0mbeta_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_string_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m    782\u001b[0m     \"\"\"\n\u001b[1;32m    783\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error: 354.3197000648747\n",
      "trees in this forest:  100\n",
      "Score for:  Fox News with  100  trees\n",
      "0.5852090032154341\n",
      "reconstruction error: 352.02396754845097\n",
      "trees in this forest:  100\n",
      "Score for:  National Review with  100  trees\n",
      "0.4204417217475415\n",
      "reconstruction error: 336.28201629888196\n",
      "trees in this forest:  100\n",
      "Score for:  New York Post with  100  trees\n",
      "0.2956039558680615\n",
      "reconstruction error: 327.6000047474941\n",
      "trees in this forest:  100\n",
      "Score for:  Breitbart with  100  trees\n",
      "0.3670997855430806\n",
      "reconstruction error: 353.5634723711977\n",
      "trees in this forest:  100\n",
      "Score for:  Buzzfeed News with  100  trees\n",
      "0.365471775854965\n",
      "reconstruction error: 353.6136038001564\n",
      "trees in this forest:  100\n",
      "Score for:  Vox with  100  trees\n",
      "0.38366686880937945\n",
      "reconstruction error: 350.8494738923189\n",
      "trees in this forest:  100\n",
      "Score for:  Atlantic with  100  trees\n",
      "0.44351581000139295\n",
      "reconstruction error: 345.87968384849387\n",
      "trees in this forest:  100\n",
      "Score for:  Washington Post with  100  trees\n",
      "0.39202807270109774\n",
      "reconstruction error: 344.94111288788616\n",
      "trees in this forest:  100\n",
      "Score for:  CNN with  100  trees\n",
      "0.2924791086350975\n"
     ]
    }
   ],
   "source": [
    "test_grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction error: 350.8494738923189\n",
      "topic 0\n",
      "--> says like people one women time get think know even life new first way would years really going us said\n",
      "\n",
      "topic 1\n",
      "--> trump president donald republican house campaign cruz obama white said republicans election would gop presidential party administration nominee senate democrats\n",
      "\n",
      "topic 2\n",
      "--> said police state u attack court officers officials syria security government islamic told killed city department military president law russia\n",
      "\n",
      "topic 3\n",
      "--> percent billion company u said 1 million market companies year 2 new bank tax growth would china 0 5 oil\n",
      "\n",
      "topic 4\n",
      "--> clinton sanders hillary democratic campaign voters state presidential bernie emails election party email fbi candidate democrats obama vote nominee comey\n",
      "\n",
      "topic 5\n",
      "--> mr ms said mrs united j new would _____ york party f b states years senator former european times lawyer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outlets =['Fox News','National Review','National Review','New York Post','Breitbart',\n",
    "              'Buzzfeed News','Vox','Atlantic','Washington Post','CNN']\n",
    "leanings_dict = {'Fox News':1,'National Review':1,'National Review':1,'New York Post':1,'Breitbart':1,\n",
    "        'Buzzfeed News':0,'Vox':0,'Atlantic':0,'Washington Post':0,'CNN':0}\n",
    "\n",
    "data = read_in_raw_data()\n",
    "\n",
    "heldout_outlet = 'Atlantic'\n",
    "#tmp = [train_outlet for train_outlets in outlets if train_outlet != outlet]\n",
    "train_data, test_data = get_test_train(heldout_outlet,data)\n",
    "#model specific below\n",
    "vectorizer, vocabulary, nmf = build_nmf(heldout_outlet,train_data)\n",
    "vectorized_train_data = vectorizer(train_data['content'])\n",
    "components = nmf.transform(vectorized_train_data)\n",
    "rand_forest = train_random_forest(cleaned_train_data, _, cleaned_train_y)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_train_data = vectorizer(train_data['content'])\n",
    "components = nmf.transform(vectorized_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135391, 5000)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to test a rf\n",
    "\n",
    "cleaned_train_data, cleaned_train_df, cleaned_train_y = remove_weak_outlets(outlets,leanings_dict,components,train_data['publication'])\n",
    "test_data=test_data.reset_index(drop=True)\n",
    "test_X = nmf.transform(vectorizer(test_data['content'])) #pd.Series([vectorizer(article) for article in test_data['content']])\n",
    "pub_type = leanings_dict[test_data['publication'][0]]\n",
    "test_y = pd.Series([pub_type for i in range(0,len(test_data))])\n",
    "rand_forest = train_random_forest(cleaned_train_data, _, cleaned_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_data, cleaned_train_df, cleaned_train_y = remove_weak_outlets(outlets,leanings_dict,components,train_data['publication'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=test_data.reset_index(drop=True)\n",
    "test_X = nmf.transform(vectorizer(test_data['content'])) #pd.Series([vectorizer(article) for article in test_data['content']])\n",
    "\n",
    "pub_type = leanings_dict[test_data['publication'][0]]\n",
    "test_y = pd.Series([pub_type for i in range(0,len(test_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73206</td>\n",
       "      <td>Obama: Reaching Out to Adversaries, Alienating...</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Uri Friedman</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a presidential candidate, Barack Obama prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73207</td>\n",
       "      <td>George Michael and Carrie Fisher: The Week in ...</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>The Editors</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>George Michael Mattered Beyond the MusicWesley...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73208</td>\n",
       "      <td>The New Reality TV</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Megan Garber</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>“Reality seems tired. It seems derivative,” a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73209</td>\n",
       "      <td>5 Numbers That Explain Education in 2016</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Emily DeRuy</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a writer, I generally favor words over numb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73210</td>\n",
       "      <td>The Atlantic  Politics &amp; Policy Daily: Happy G...</td>\n",
       "      <td>Atlantic</td>\n",
       "      <td>Candice Norwood</td>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This article is part of a feature we a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title publication  \\\n",
       "0  73206  Obama: Reaching Out to Adversaries, Alienating...    Atlantic   \n",
       "1  73207  George Michael and Carrie Fisher: The Week in ...    Atlantic   \n",
       "2  73208                                 The New Reality TV    Atlantic   \n",
       "3  73209           5 Numbers That Explain Education in 2016    Atlantic   \n",
       "4  73210  The Atlantic  Politics & Policy Daily: Happy G...    Atlantic   \n",
       "\n",
       "            author        date    year  month  url  \\\n",
       "0     Uri Friedman  2016-12-31  2016.0   12.0  NaN   \n",
       "1      The Editors  2016-12-31  2016.0   12.0  NaN   \n",
       "2     Megan Garber  2016-12-31  2016.0   12.0  NaN   \n",
       "3      Emily DeRuy  2016-12-31  2016.0   12.0  NaN   \n",
       "4  Candice Norwood  2016-12-30  2016.0   12.0  NaN   \n",
       "\n",
       "                                             content  \n",
       "0  As a presidential candidate, Barack Obama prom...  \n",
       "1  George Michael Mattered Beyond the MusicWesley...  \n",
       "2  “Reality seems tired. It seems derivative,” a ...  \n",
       "3  As a writer, I generally favor words over numb...  \n",
       "4          This article is part of a feature we a...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = train_random_forest(cleaned_train_data, _, cleaned_train_y)\n",
    "#train_random_forest(nmf_compenents, raw_training_data, cleaned_train_y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4592561638111158"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Breitbart          23781\n",
       "New York Post      17493\n",
       "CNN                11488\n",
       "Washington Post    11114\n",
       "National Review     6203\n",
       "Vox                 4947\n",
       "Buzzfeed News       4854\n",
       "Fox News            4354\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(cleaned_train_y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17283</td>\n",
       "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17284</td>\n",
       "      <td>Rift Between Officers and Residents as Killing...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Benjamin Mueller and Al Baker</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After the bullet shells get counted, the blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17285</td>\n",
       "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Margalit Fox</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17286</td>\n",
       "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>William McDonald</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17287</td>\n",
       "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Choe Sang-Hun</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title     publication  \\\n",
       "0  17283  House Republicans Fret About Winning Their Hea...  New York Times   \n",
       "1  17284  Rift Between Officers and Residents as Killing...  New York Times   \n",
       "2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...  New York Times   \n",
       "3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...  New York Times   \n",
       "4  17287  Kim Jong-un Says North Korea Is Preparing to T...  New York Times   \n",
       "\n",
       "                          author        date    year  month  url  \\\n",
       "0                     Carl Hulse  2016-12-31  2016.0   12.0  NaN   \n",
       "1  Benjamin Mueller and Al Baker  2017-06-19  2017.0    6.0  NaN   \n",
       "2                   Margalit Fox  2017-01-06  2017.0    1.0  NaN   \n",
       "3               William McDonald  2017-04-10  2017.0    4.0  NaN   \n",
       "4                  Choe Sang-Hun  2017-01-02  2017.0    1.0  NaN   \n",
       "\n",
       "                                             content  \n",
       "0  WASHINGTON  —   Congressional Republicans have...  \n",
       "1  After the bullet shells get counted, the blood...  \n",
       "2  When Walt Disney’s “Bambi” opened in 1942, cri...  \n",
       "3  Death may be the great equalizer, but it isn’t...  \n",
       "4  SEOUL, South Korea  —   North Korea’s leader, ...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          New York Times\n",
       "1          New York Times\n",
       "2          New York Times\n",
       "3          New York Times\n",
       "4          New York Times\n",
       "5          New York Times\n",
       "6          New York Times\n",
       "7          New York Times\n",
       "8          New York Times\n",
       "9          New York Times\n",
       "10         New York Times\n",
       "11         New York Times\n",
       "12         New York Times\n",
       "13         New York Times\n",
       "14         New York Times\n",
       "15         New York Times\n",
       "16         New York Times\n",
       "17         New York Times\n",
       "18         New York Times\n",
       "19         New York Times\n",
       "20         New York Times\n",
       "21         New York Times\n",
       "22         New York Times\n",
       "23         New York Times\n",
       "24         New York Times\n",
       "25         New York Times\n",
       "26         New York Times\n",
       "27         New York Times\n",
       "28         New York Times\n",
       "29         New York Times\n",
       "               ...       \n",
       "142540    Washington Post\n",
       "142541    Washington Post\n",
       "142542    Washington Post\n",
       "142543    Washington Post\n",
       "142544    Washington Post\n",
       "142545    Washington Post\n",
       "142546    Washington Post\n",
       "142547    Washington Post\n",
       "142548    Washington Post\n",
       "142549    Washington Post\n",
       "142550    Washington Post\n",
       "142551    Washington Post\n",
       "142552    Washington Post\n",
       "142553    Washington Post\n",
       "142554    Washington Post\n",
       "142555    Washington Post\n",
       "142556    Washington Post\n",
       "142557    Washington Post\n",
       "142558    Washington Post\n",
       "142559    Washington Post\n",
       "142560    Washington Post\n",
       "142561    Washington Post\n",
       "142562    Washington Post\n",
       "142563    Washington Post\n",
       "142564    Washington Post\n",
       "142565    Washington Post\n",
       "142566    Washington Post\n",
       "142567    Washington Post\n",
       "142568    Washington Post\n",
       "142569    Washington Post\n",
       "Name: publication, Length: 135391, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['publication']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 5000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.components_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Breitbart              23781\n",
       "New York Post          17493\n",
       "NPR                    11992\n",
       "CNN                    11488\n",
       "Washington Post        11114\n",
       "Reuters                10710\n",
       "Guardian                8681\n",
       "New York Times          7803\n",
       "Atlantic                7179\n",
       "Business Insider        6757\n",
       "National Review         6203\n",
       "Talking Points Memo     5214\n",
       "Vox                     4947\n",
       "Buzzfeed News           4854\n",
       "Fox News                4354\n",
       "Name: publication, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df_full['publication'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df_full[(g_df_full['publication'] != heldout)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     137716\n",
       "False      4854\n",
       "Name: publication, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(g_df_full['publication'] != 'Buzzfeed News').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
